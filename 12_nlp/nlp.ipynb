{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Проект-для-«Викишоп»-c-BERT\" data-toc-modified-id=\"Проект-для-«Викишоп»-c-BERT-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Проект для «Викишоп» c BERT</a></span><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Настройка-окружения\" data-toc-modified-id=\"Настройка-окружения-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Настройка окружения</a></span></li><li><span><a href=\"#Чтение-файла\" data-toc-modified-id=\"Чтение-файла-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>Чтение файла</a></span></li><li><span><a href=\"#Подготовка-корпусов\" data-toc-modified-id=\"Подготовка-корпусов-1.1.3\"><span class=\"toc-item-num\">1.1.3&nbsp;&nbsp;</span>Подготовка корпусов</a></span></li><li><span><a href=\"#BERT\" data-toc-modified-id=\"BERT-1.1.4\"><span class=\"toc-item-num\">1.1.4&nbsp;&nbsp;</span>BERT</a></span></li><li><span><a href=\"#Подготовка-выборок\" data-toc-modified-id=\"Подготовка-выборок-1.1.5\"><span class=\"toc-item-num\">1.1.5&nbsp;&nbsp;</span>Подготовка выборок</a></span></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Результаты-исследования\" data-toc-modified-id=\"Результаты-исследования-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Результаты исследования</a></span><ul class=\"toc-item\"><li><span><a href=\"#Общие-выводы\" data-toc-modified-id=\"Общие-выводы-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Общие выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп» c BERT\n",
    "<p>\n",
    "<div align=\"right\"><b>Спринт 12 | Когорта ДС13 | Артур Урусов</b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>\n",
    "<p>Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "<p>Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "    \n",
    "<p> Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Настройка окружения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import torch\n",
    "import warnings\n",
    "import transformers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import notebook\n",
    "from catboost import CatBoostClassifier\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from keras.preprocessing.text import text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATE = 42\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, настроена ли CUDA для работы с BERT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: GeForce RTX 2070 SUPER\n"
     ]
    }
   ],
   "source": [
    "# Если доступен GPU...\n",
    "if torch.cuda.is_available():        \n",
    "    # Скажем PyTorch использовать GPU.    \n",
    "    device = torch.device(\"cuda\")    \n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())    \n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "# Если нет...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Чтение файла"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прочитаем данные в датафрейм."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets\\\\toxic_comments.csv')\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, нет ли лишних значений в столбце `toxic`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toxic'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изучим баланс классов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toxic</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>143346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         text\n",
       "toxic        \n",
       "0      143346\n",
       "1       16225"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('toxic').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, токсичные комментарии составляют всего лишь около 10% от датасета.\n",
    "\n",
    "Проверим сколько строк с латиницей, и сколько с кириллицей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latin text: 159564\n",
      "Cyrillic text: 259\n"
     ]
    }
   ],
   "source": [
    "print('Latin text:', df[df['text'].str.findall(r'[a-zA-Z]').str.len() > 0].shape[0])\n",
    "print('Cyrillic text:', df[df['text'].str.findall(r'[а-яА-ЯёЁ]').str.len() > 0].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, подавляющее большинство текста на латинице, то есть скорее всего датасет на английском языке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем выборку для работы с BERT, но выровняем баланс классов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allright, the fact that I don't agree with you...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naughty naughty u slimy little greaseball. \\n\\...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It's like watching a rabid poodle try to bite ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UFC 191 \\n\\nTHIS IS THE FINALIZED BOUT ORDER, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"\\nGreat! Thanks ;)  TALK! \"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32445</th>\n",
       "      <td>God I'm fucking scared I won't be able to vand...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32446</th>\n",
       "      <td>FUCK THA WORLD AND FUCK SINNEED AND FUCK FT2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32447</th>\n",
       "      <td>Don't even start with me Mr. Confused Gender. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32448</th>\n",
       "      <td>Banning Fut.Perf. ☼ from this Page \\n\\nThis se...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32449</th>\n",
       "      <td>Dude, who fears banning. This is what U HINDU ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32450 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  toxic\n",
       "0      Allright, the fact that I don't agree with you...      0\n",
       "1      Naughty naughty u slimy little greaseball. \\n\\...      1\n",
       "2      It's like watching a rabid poodle try to bite ...      1\n",
       "3      UFC 191 \\n\\nTHIS IS THE FINALIZED BOUT ORDER, ...      1\n",
       "4                           \"\\nGreat! Thanks ;)  TALK! \"      0\n",
       "...                                                  ...    ...\n",
       "32445  God I'm fucking scared I won't be able to vand...      1\n",
       "32446       FUCK THA WORLD AND FUCK SINNEED AND FUCK FT2      1\n",
       "32447  Don't even start with me Mr. Confused Gender. ...      1\n",
       "32448  Banning Fut.Perf. ☼ from this Page \\n\\nThis se...      1\n",
       "32449  Dude, who fears banning. This is what U HINDU ...      1\n",
       "\n",
       "[32450 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones = df[df['toxic'] == 1]\n",
    "zeros = df[df['toxic'] == 0].sample(len(ones))\n",
    "sample = pd.concat([ones, zeros], axis=0)\n",
    "sample = sample.sample(frac=1)\n",
    "sample.reset_index(drop=True, inplace=True)\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим баланс классов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toxic</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text\n",
       "toxic       \n",
       "0      16225\n",
       "1      16225"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.groupby('toxic').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Баланс классов соблюдён."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка корпусов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим корпус:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127656,) (127656,) (31915,) (31915,)\n"
     ]
    }
   ],
   "source": [
    "corpus_X = df['text'].values.astype('U')\n",
    "corpus_y = df['toxic']\n",
    "corpus_X_train, corpus_X_test, corpus_y_train, corpus_y_test = train_test_split(\n",
    "    corpus_X, corpus_y, random_state=STATE, test_size=.2\n",
    ")\n",
    "print(corpus_X_train.shape, corpus_y_train.shape, corpus_X_test.shape, corpus_y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подгрузим словарь стоп-слов английского языка и напишем функции для очищения и токенизации текста, а также для разделения нескольких наборов данных на выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\arthr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    t = str.maketrans(dict.fromkeys(\"'`'\", \"\"))\n",
    "    text = text.translate(t)\n",
    "    return ' '.join(re.sub(r'[^a-zA-Z ]', ' ', text).split())\n",
    "\n",
    "\n",
    "def keras_tokenize(text):\n",
    "    text = clean_text(text)\n",
    "    tokens = text_to_word_sequence(text)\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "\n",
    "def multi_split(X, y, random_state=None, test_size=.2, stratify=None):\n",
    "    X_train, X_test, y_train, y_test = [], [], [], []\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        X_tr, X_t, y_tr, y_t = train_test_split(\n",
    "            X[i], y[i], random_state=random_state, test_size=test_size, stratify=stratify[i]\n",
    "        )\n",
    "        \n",
    "        X_train.append(X_tr)\n",
    "        X_test.append(X_t)\n",
    "        y_train.append(y_tr)\n",
    "        y_test.append(y_t)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим очищенный корпус."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10a53a5ec1854006a81b466ac29668ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/127656 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clean_corpus_X_train = []\n",
    "for i in notebook.tqdm(range(len(corpus_X_train))):\n",
    "    clean_corpus_X_train.append(keras_tokenize(corpus_X_train[i]))\n",
    "    \n",
    "clean_corpus_X_train = np.array(clean_corpus_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edf5eb70a01c4c5d937471e0c5756285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31915 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clean_corpus_X_test = []\n",
    "for i in notebook.tqdm(range(len(corpus_X_test))):\n",
    "    clean_corpus_X_test.append(keras_tokenize(corpus_X_test[i]))\n",
    "    \n",
    "clean_corpus_X_test = np.array(clean_corpus_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходный текст: \n",
      " Grandma Terri Should Burn in Trash \n",
      "Grandma Terri is trash. I hate Grandma Terri. F%%K her to HELL! 71.74.76.40\n",
      "Очищенный и лемматизированный текст: \n",
      " grandma terri should burn in trash grandma terri is trash i hate grandma terri f k her to hell\n"
     ]
    }
   ],
   "source": [
    "print(\"Исходный текст: \\n\", corpus_X_train[0])\n",
    "print(\"Очищенный и лемматизированный текст: \\n\", clean_corpus_X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим переменные для мешков, n-грамм и TF-IDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер мешка без учёта стоп-слов: (31915, 165785)\n",
      "Размер очищенного мешка без учёта стоп-слов: (31915, 152799)\n"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer()\n",
    "count_vect.fit(corpus_X_train)\n",
    "bow = count_vect.transform(corpus_X_test)\n",
    "count_vect.fit(clean_corpus_X_train)\n",
    "bow_cl = count_vect.transform(clean_corpus_X_test)\n",
    "print(\"Размер мешка без учёта стоп-слов:\", bow.shape)\n",
    "print(\"Размер очищенного мешка без учёта стоп-слов:\", bow_cl.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер мешка с учётом стоп-слов: (31915, 165640)\n",
      "Размер очищенного мешка с учётом стоп-слов: (31915, 152656)\n"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer(stop_words=stop_words)\n",
    "count_vect.fit(corpus_X_train)\n",
    "bow_sw = count_vect.transform(corpus_X_test)\n",
    "count_vect.fit(clean_corpus_X_train)\n",
    "bow_sw_cl = count_vect.transform(clean_corpus_X_test)\n",
    "print(\"Размер мешка с учётом стоп-слов:\", bow_sw.shape)\n",
    "print(\"Размер очищенного мешка с учётом стоп-слов:\", bow_sw_cl.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер: (31915, 1932725)\n",
      "Размер очищенных n-грамм: (31915, 1870998)\n"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer(ngram_range=(2, 2))\n",
    "count_vect.fit(corpus_X_train)\n",
    "n_gramm = count_vect.transform(corpus_X_test)\n",
    "count_vect.fit(clean_corpus_X_train)\n",
    "n_gramm_cl = count_vect.transform(clean_corpus_X_test)\n",
    "print(\"Размер:\", n_gramm.shape)\n",
    "print(\"Размер очищенных n-грамм:\", n_gramm_cl.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер матрицы: (31915, 165640)\n",
      "Размер очищенной матрицы: (31915, 152656)\n"
     ]
    }
   ],
   "source": [
    "count_tf_idf = TfidfVectorizer(stop_words=stop_words)\n",
    "count_tf_idf.fit(corpus_X_train)\n",
    "tf_idf = count_tf_idf.transform(corpus_X_test)\n",
    "count_tf_idf.fit(clean_corpus_X_train)\n",
    "tf_idf_cl = count_tf_idf.transform(clean_corpus_X_test)\n",
    "print(\"Размер матрицы:\", tf_idf.shape)\n",
    "print(\"Размер очищенной матрицы:\", tf_idf_cl.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь перейдём к BERT. Для начала создадим модели для токенизации и эмбеддинга (используем *BERT base uncased*):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.BertTokenizerFast.from_pretrained(\n",
    "    'bert-base-uncased', \n",
    "    do_lower_case=True\n",
    ")\n",
    "model = transformers.BertModel.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    num_labels=2,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False\n",
    ")\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Токенизируем тексты, а затем приведем их к единому размеру и сделаем маски."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1212 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "tokenized = sample['text'].apply(\n",
    "    lambda x: tokenizer.encode(x, add_special_tokens=True)\n",
    ")\n",
    "max_len = len(max(tokenized.values, key=len))\n",
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "attention_mask = np.where(padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обрубим токенизированные тексты по максимальному значению текущей модели BERT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512,)\n",
      "(512,)\n"
     ]
    }
   ],
   "source": [
    "truncated = padded[:,:512]\n",
    "truncated_attention_mask = attention_mask[:,:512]\n",
    "\n",
    "print(truncated[0].shape)\n",
    "print(truncated_attention_mask[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь преобразуем тексты в эмбеддинги:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f34f8348702544e3a412720f59fc455a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "embeddings = []\n",
    "\n",
    "for i in notebook.tqdm(range(truncated.shape[0] // batch_size)):\n",
    "    batch = torch.cuda.LongTensor(truncated[batch_size*i:batch_size*(i+1)])\n",
    "    attention_mask_batch = torch.cuda.LongTensor(truncated_attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "\n",
    "    embeddings.append(batch_embeddings[0][:,0,:].cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка выборок"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем выборку BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = batch_size * (truncated.shape[0] // batch_size)\n",
    "bert_features = pd.DataFrame(np.concatenate(embeddings), index=sample['toxic'][:end].index)\n",
    "bert_target = sample['toxic'][:end]\n",
    "\n",
    "del embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И разделим все выборки на трейн и тест."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [bow, bow_cl, bow_sw, bow_sw_cl, n_gramm, n_gramm_cl, tf_idf, tf_idf_cl] + [bert_features]\n",
    "y = [corpus_y_test] * (len(X) - 1) + [bert_target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = multi_split(X, y, random_state=STATE, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим объявленные переменные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoostClassifier\t CountVectorizer\t LogisticRegression\t STATE\t TfidfVectorizer\t X\t X_test\t X_train\t attention_mask\t \n",
      "attention_mask_batch\t batch\t batch_embeddings\t batch_size\t bert_features\t bert_target\t bow\t bow_cl\t bow_sw\t \n",
      "bow_sw_cl\t clean_corpus_X_test\t clean_corpus_X_train\t clean_text\t corpus_X\t corpus_X_test\t corpus_X_train\t corpus_y\t corpus_y_test\t \n",
      "corpus_y_train\t count_tf_idf\t count_vect\t device\t df\t end\t f1_score\t i\t keras_tokenize\t \n",
      "max_len\t model\t multi_split\t n_gramm\t n_gramm_cl\t nltk\t notebook\t np\t ones\t \n",
      "padded\t pd\t re\t sample\t stop_words\t stopwords\t text_to_word_sequence\t tf_idf\t tf_idf_cl\t \n",
      "tokenized\t tokenizer\t torch\t train_test_split\t transformers\t truncated\t truncated_attention_mask\t warnings\t y\t \n",
      "y_test\t y_train\t zeros\t \n"
     ]
    }
   ],
   "source": [
    "%who"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И очистим память."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.zero_grad()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "del X, attention_mask, attention_mask_batch, batch, batch_embeddings, batch_size, bert_features, bert_target, bow, \\\n",
    "bow_cl, bow_sw, bow_sw_cl, clean_corpus_X_test, clean_corpus_X_train, clean_text, corpus_X, corpus_X_test, \\\n",
    "corpus_X_train, corpus_y, corpus_y_test, corpus_y_train, count_tf_idf, count_vect, device, end, i, max_len, model, \\\n",
    "n_gramm, n_gramm_cl, ones, padded, sample, stop_words, tf_idf, tf_idf_cl, tokenized, truncated, \\\n",
    "truncated_attention_mask, y, zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь напишем функцию для тестирования модели и на её основе ещё одну, для тестирования на нескольких выборках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_test(clf, X_train, y_train, X_test, y_test, label='', verbose=True):\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    train_score = round(f1_score(y_train, clf.predict(X_train)), 4)\n",
    "    test_score = round(f1_score(y_test, clf.predict(X_test)), 4)\n",
    "    if verbose:\n",
    "        print(f'== {clf.__class__.__name__}{label} ==')\n",
    "        print(f'F1 train: {train_score}')\n",
    "        print(f'F1 test:  {test_score}')\n",
    "        print()\n",
    "    \n",
    "    return pd.DataFrame(\n",
    "        [[f'{clf.__class__.__name__}{label}', train_score, test_score]], \n",
    "        columns=['model', 'train_score', 'test_score']\n",
    "    )\n",
    "\n",
    "\n",
    "def multi_sample_test(clf, X_train, y_train, X_test, y_test, labels=[], params=None, verbose=True):\n",
    "    stats = pd.DataFrame(columns=['model', 'train_score', 'test_score'])\n",
    "    \n",
    "    for i in range(len(X_train)):\n",
    "        model = clf(**params)\n",
    "        stats = pd.concat([\n",
    "            stats, \n",
    "            model_test(model, X_train[i], y_train[i], X_test[i], y_test[i], label=labels[i], verbose=verbose)\n",
    "        ])\n",
    "        \n",
    "    return stats.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обозначим постфиксы для результатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['_bow', '_bow_cl', '_bow_sw', '_bow_sw_cl', '_n_gramm', '_n_gramm_cl', '_tf_idf', '_tf_idf_cl', '_bert']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим какой результат выдаст логистическая регрессия:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== LogisticRegression_bow ==\n",
      "F1 train: 0.9431\n",
      "F1 test:  0.7298\n",
      "\n",
      "== LogisticRegression_bow_cl ==\n",
      "F1 train: 0.9393\n",
      "F1 test:  0.7257\n",
      "\n",
      "== LogisticRegression_bow_sw ==\n",
      "F1 train: 0.9333\n",
      "F1 test:  0.7206\n",
      "\n",
      "== LogisticRegression_bow_sw_cl ==\n",
      "F1 train: 0.9301\n",
      "F1 test:  0.724\n",
      "\n",
      "== LogisticRegression_n_gramm ==\n",
      "F1 train: 0.9352\n",
      "F1 test:  0.4872\n",
      "\n",
      "== LogisticRegression_n_gramm_cl ==\n",
      "F1 train: 0.9299\n",
      "F1 test:  0.4904\n",
      "\n",
      "== LogisticRegression_tf_idf ==\n",
      "F1 train: 0.6459\n",
      "F1 test:  0.5858\n",
      "\n",
      "== LogisticRegression_tf_idf_cl ==\n",
      "F1 train: 0.6522\n",
      "F1 test:  0.5991\n",
      "\n",
      "== LogisticRegression_bert ==\n",
      "F1 train: 0.9083\n",
      "F1 test:  0.8905\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lrm_params = dict(\n",
    "    max_iter=1000, \n",
    "    random_state=STATE\n",
    ")\n",
    "stats = multi_sample_test(LogisticRegression, X_train, y_train, X_test, y_test, labels=labels, params=lrm_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также проверим BERT выборку на CatBoostClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: less than 75% gpu memory available for training. Free: 5913.4375 Total: 8192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== CatBoostClassifier_bert ==\n",
      "F1 train: 0.9298\n",
      "F1 test:  0.871\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cbm = CatBoostClassifier(\n",
    "    silent=True,\n",
    "    iterations=100,\n",
    "    loss_function='Logloss',\n",
    "    task_type='GPU',\n",
    "    devices='0'\n",
    ")\n",
    "stats = pd.concat([stats, model_test(cbm, X_train[8], y_train[8], X_test[8], y_test[8], label='_bert')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Результаты исследования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Общие выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Укажем пороговое значение метрики f1 и отсортируем результаты в порядке убывания:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression_bert</td>\n",
       "      <td>0.9083</td>\n",
       "      <td>0.8905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoostClassifier_bert</td>\n",
       "      <td>0.9298</td>\n",
       "      <td>0.8710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BASELINE</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression_bow</td>\n",
       "      <td>0.9431</td>\n",
       "      <td>0.7298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression_bow_cl</td>\n",
       "      <td>0.9393</td>\n",
       "      <td>0.7257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression_bow_sw_cl</td>\n",
       "      <td>0.9301</td>\n",
       "      <td>0.7240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression_bow_sw</td>\n",
       "      <td>0.9333</td>\n",
       "      <td>0.7206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression_tf_idf_cl</td>\n",
       "      <td>0.6522</td>\n",
       "      <td>0.5991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression_tf_idf</td>\n",
       "      <td>0.6459</td>\n",
       "      <td>0.5858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression_n_gramm_cl</td>\n",
       "      <td>0.9299</td>\n",
       "      <td>0.4904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression_n_gramm</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>0.4872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            model  train_score  test_score\n",
       "0         LogisticRegression_bert       0.9083      0.8905\n",
       "1         CatBoostClassifier_bert       0.9298      0.8710\n",
       "2                        BASELINE       0.7500      0.7500\n",
       "3          LogisticRegression_bow       0.9431      0.7298\n",
       "4       LogisticRegression_bow_cl       0.9393      0.7257\n",
       "5    LogisticRegression_bow_sw_cl       0.9301      0.7240\n",
       "6       LogisticRegression_bow_sw       0.9333      0.7206\n",
       "7    LogisticRegression_tf_idf_cl       0.6522      0.5991\n",
       "8       LogisticRegression_tf_idf       0.6459      0.5858\n",
       "9   LogisticRegression_n_gramm_cl       0.9299      0.4904\n",
       "10     LogisticRegression_n_gramm       0.9352      0.4872"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = pd.concat([stats, pd.DataFrame([['BASELINE', .75, .75]], columns=['model', 'train_score', 'test_score'])])\n",
    "stats.sort_values(by='test_score', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом исследовании мы обучали модель для предсказания токсичности текста.\n",
    "\n",
    "Для работы нам предоставили датасет с текстами и целевым признаком (токсичный текст или нет).\n",
    "\n",
    "Сначала мы подготовили корпус и сделали из него несколько выборок: мешки, биграммы, TF-IDF.\n",
    "\n",
    "Далее мы провели работу с моделью BERT, токенизировали тексты и преобразовали их в эмбеддинги.\n",
    "\n",
    "После этого мы создали выборки и обучили на них логистическую регрессию. Кроме того, на BERT-выборке мы обучили и Catboost.\n",
    "\n",
    "Требуемый результат выше .75 f1 показали только модели, обученные на эмбеддингах BERT. При этом логистическая регрессия показала налучший результат. Остальные модели не смогли достигнуть требуемого результата.\n",
    "\n",
    "В итоге, для предсказания токсичности текста можно использовать логистическую регрессию, обученную на эмбеддингах BERT. Однако, вероятно, при более тщательном подборе параметров и другие варианты смогутдостичь требуемого результата."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [x]  Весь код выполняется без ошибок\n",
    "- [x]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [x]  Данные загружены и подготовлены\n",
    "- [x]  Модели обучены\n",
    "- [x]  Значение метрики *F1* не меньше 0.75\n",
    "- [x]  Выводы написаны"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
